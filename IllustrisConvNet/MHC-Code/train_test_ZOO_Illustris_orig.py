def train_convnet_GZOO(X,Y,ntrain,nval,test_name):


    ind=random.sample(range(0, ntrain+nval-1), ntrain+nval-1)
    X_train = X[ind[0:ntrain],:,:,:]   
    X_val = X[ind[ntrain:ntrain+nval],:,:,:]
    Y_train = Y[ind[0:ntrain],:]
    Y_val = Y[ind[ntrain:ntrain+nval],:]
    
    
    ## Params
    # model params
    batch_size = 64
    nb_epoch = 25
    data_augmentation = True
    normalize = True
    y_normalization = False
    norm_constant = 255 

    # SGD parameters
    lr=0.001   #0.01
    decay=0
    momentum=0.9   #0.9
    nesterov=True

    depth=32
    nb_dense = 64

    #output params
    verbose = 1

    print("Test name is: " + test_name)

    # input image dimensions
    img_rows, img_cols = X_train.shape[2:4]
    img_channels = 3
    print(img_rows, img_cols)

    ### Right shape for X
    X_train = X_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)
    X_val = X_val.reshape(X_val.shape[0], img_channels, img_rows, img_cols)

    #misc.imsave(pathin+"examples/X_0.jpeg",X_train[0,0,:,:])
    #misc.imsave(pathin+"examples/X_100.jpeg",X_train[100,0,:,:])
    #print X_train[0,0,32,:]
    #print X_train(1,0,:,:)
    #print X_train[100,0,32,:]
    
    model = Sequential()
    model.add(Convolution2D(32, 6,6, border_mode='same',
                        input_shape=(img_channels, img_rows, img_cols)))
    model.add(Activation('relu'))
    #model.add(Dropout(0.5))

    model.add(Convolution2D(64, 5, 5, border_mode='same'))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    #model.add(Dropout(0.25))

    model.add(Convolution2D(128, 2, 2, border_mode='same'))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    #model.add(Dropout(0.5))

    model.add(Convolution2D(128, 3, 3, border_mode='same'))
    model.add(Activation('relu'))
    #model.add(Dropout(0.25))

    model.add(Flatten())

    model.add(MaxoutDense(output_dim=128))
    model.add(Dropout(0.5))

    model.add(MaxoutDense(output_dim=128))
    model.add(Dropout(0.5))

    model.add(Dense(nparams, activation='softmax'))
    #model.add(Dropout(0.25))

    rms=rmsprop(lr=lr)
    model.compile(loss='mse',optimizer='rmsprop')




    if not data_augmentation:
        print('Not using data augmentation.')
        history = model.fit(X_train, Y_train,
                            batch_size=batch_size,
                            nb_epoch=nb_epoch,
                            validation_data=(X_val, Y_val),
                            shuffle=True,
                            verbose=verbose)
    else:
        print('Using real-time data augmentation.')

        # this will do preprocessing and realtime data augmentation
        datagen = ImageDataGenerator(
            featurewise_center=False, 
            samplewise_center=False, 
            featurewise_std_normalization=False, 
            samplewise_std_normalization=False,
            zca_whitening=False, 
            rotation_range=360,
            width_shift_range=0.05,  
            height_shift_range=0.05, 
            horizontal_flip=True,
            vertical_flip=True,
            zoom_range=[0.75,1.3])  

        
        datagen.fit(X_train)
        
        # fit the model on the batches generated by datagen.flow()
        history = model.fit_generator(datagen.flow(X_train, Y_train,
                                                   batch_size=batch_size),
                                                   samples_per_epoch=X_train.shape[0],
                                                   nb_epoch=nb_epoch,
                                                   validation_data=(X_val, Y_val),
                                                   verbose=verbose)

   
    
    print("Saving model...")
    model.save_weights(test_name+".hd5",overwrite=True)

    return

def validate_convnet_GZOO(X,model_name):
    
    ## Params
    # model params
    batch_size = 64
    nb_epoch = 50
    data_augmentation = True

    # SGD parameters
    lr=0.001   #0.01
    decay=1e-6
    momentum=0.9   #0.9
    nesterov=True
    
    # input image dimensions
    img_rows, img_cols = X.shape[2:4]
    img_channels = 3
    print(img_rows, img_cols)

    print "X", X.shape
    ### Right shape for X
    X = X.reshape(X.shape[0], img_channels, img_rows, img_cols)
   

    model = Sequential()
    model.add(Convolution2D(32, 6,6, border_mode='same',
                        input_shape=(img_channels, img_rows, img_cols)))
    model.add(Activation('relu'))
    #model.add(Dropout(0.5))

    model.add(Convolution2D(64, 5, 5, border_mode='same'))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    #model.add(Dropout(0.25))

    model.add(Convolution2D(128, 2, 2, border_mode='same'))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    #model.add(Dropout(0.5))

    model.add(Convolution2D(128, 3, 3, border_mode='same'))
    model.add(Activation('relu'))
    #model.add(Dropout(0.25))

    model.add(Flatten())

    model.add(MaxoutDense(output_dim=128))
    model.add(Dropout(0.5))

    model.add(MaxoutDense(output_dim=128))
    model.add(Dropout(0.5))

    model.add(Dense(nparams, activation='softmax'))
    #model.add(Dropout(0.25))



    rms=rmsprop(lr=lr)
    model.compile(loss='mse',optimizer='rmsprop')


    ##load model
    model.load_weights(model_name+".hd5")
    Y_pred = model.predict(X)

    return Y_pred
    

def extract_thumb(im,x,y,size):
    if size %2==0:
        size = size+1
    print(size)
    print(x)
    print(im.shape)
    up_x=int(x-size/2)
    dow_x=int(x+size/2)
    up_y=int(y-size/2)
    dow_y=int(y+size/2)
    res=im[up_x:dow_x,up_y:dow_y]        
    return res

def read_data(pathin,maxim):
    size_im=64
    size_crop=192

    data=fits.getdata(pathin+'training_kaggle.fit',1)
    idcat=data['GalaxyID']
    #sizev=data['petroR90_r_pix']
    #avg_size=np.mean(sizev)
    nparams=3
    maxim=60000L; # 48000
    D=np.zeros([maxim+1,3,size_im,size_im])
    #D45=np.zeros([maxim+1,1,size_im,size_im])
    Y=np.zeros([maxim+1,nparams])
    idvec=np.zeros([maxim+1], dtype=np.long)
    iteri=-1;
    numim=0;
    numim_init=numim
    catalog=Table(data)

    list=glob.glob('/home/marc/data/SDSS/ZOO/*.jpg')

    while iteri<maxim:
        try:
            #print(str(idvec[0]).zfill(6))
            #numgal=idcat[numim]
            file=list[numim]
            spl=file.split("/")
            filename=spl[7]
            numgal=filename.split(".")
            numgal=long(numgal[0])
            #size=sizev[numim]
            namegal=str(numgal)+".jpg"        
            #hdulist = fits.open(pathin+namegal)
            scidata = misc.imread(namegal)
            f=np.nonzero(data['GalaxyID']==numgal);
            #size=data['petroR90_r_pix'][f]
            print('reading: '+pathin+namegal)        
        except:
            print("Galaxy number %d is missing" % (numim))
            print(namegal)
            numim += 1
            continue
        #scidata1 = hdulist[0].data
        #lx,ly=scidata1.shape
        #if lx<113:
        #   numim+=1
        #    continue
    
        #scidata1 = hdulist[0].data
        lx,ly, lz=scidata.shape
        print "LX", lx
        if lx < 256 or ly<256:
            print "ENTRO"
            numim += 1
            continue
        #x = np.arange(lx) - (lx-1)/2.  
        #y = np.arange(ly) - (ly-1)/2.
        #A, B = np.meshgrid(x, y)
        #d = np.sqrt(A**2 + B**2)
        #scidata1[np.transpose(d)>size*1.2]=0
        print lx,ly
        #fact=avg_size/size
        #print "FACT:", size, avg_size,fact
        #if fact==0:
        #    fact=1
        #scidata=scidata1[:,:,0]
        #for i in [0,1,2]:
        #max1=(scidata1[:,:,0]).max()
        #max2=(scidata1[:,:,1]).max()
        #max3=(scidata1[:,:,2]).max()
        #mv=[max1,max2,max3]
        #pos=np.argmax(mv)
        #scidata=scidata1[:,:,0]
        #scidata=zoom(scidata1[:,:,0], fact[0], order=3)
        print "SHAPE ", scidata.shape
        lx,ly, lz=scidata.shape
        #fact=1        
        #if size < 10 or size > 50:
        #    numim+=1
        #    continue
        if lx<size_im:
            numim += 1
            continue
        scidata = extract_thumb(scidata,int(lx/2.0),int(ly/2.0),size_im)
        #scidata1 = imresize(scidata1,(size_im,size_im,3))
        #hdulist.close()
        #scidata = (scidata1/1000.)
        #max_center=np.amax(scidata[size_im/2-4:size_im/2+4,size_im/2-4:size_im/2+4])
        #if max_center != scidata.max():
        #    numim+=1
        #    continue
        #scidata = scidata/max_center
        iteri=iteri+1
        scidata = np.transpose(scidata)
        print "MAX:", scidata.max()
        #scidata = np.expand_dims(scidata, axis=0)
        #scidata = np.expand_dims(scidata, axis=0)
        print scidata.shape
        D[iteri,:,:,:]=scidata
        #scidata45=scidata
        #scidata45 = extract_thumb(scidata45,int(lx/2.0),int(ly/2.0),size_im)
        #D45[iteri,:,:,:]=scidata45
        #if iteri%10 ==0:        
        #    hdu_w = fits.PrimaryHDU(scidata)
        #    stamp_name=pathin+"examples_stamps/"+str(numgal)+"_stamp_r.fits"
        #   hdu_w.writeto(stamp_name, clobber=True)
        #    misc.imsave(pathin+"examples/"+filename,np.transpose(scidata))
    
        Y[iteri,0]=data['Class1.1'][f]
        print Y[iteri,0], numgal
        Y[iteri,1]=data['Class1.2'][f]
        Y[iteri,2]=data['Class1.3'][f]
        idvec[iteri]=data['GalaxyID'][f]  
        numim=numim+1
        print "ITER:",iteri
        Y = Y.squeeze()


        np.save(pathin+"image_vector"+str(maxim)+".npy",D) 
        np.save(pathin+"target_vector"+str(maxim)+".npy",Y) 

from astropy.io import fits
from astropy.table import Table
from math import log10
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
from astropy.modeling.models import Sersic2D
import os
from scipy.misc import imresize
os.environ["THEANO_FLAGS"] = "mode=FAST_RUN,device=gpu,floatX=float32"
from scipy import misc
from scipy.ndimage import zoom
from scipy.ndimage.interpolation import rotate
import glob
import theano
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten, MaxoutDense
from keras.engine.topology import Merge
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.optimizers import rmsprop
import random

ntrainv=[50000L]

for i in ntrainv:
    maxim=60000L
    ntrain=i
    nval=i/10
    npred=5000L
    pred_index=51000L
    pathin="/home/marc/data/SDSS/ZOO/"
    nparams=3

    #read_data(pathin,maxim)

    D=np.load(pathin+"image_vector"+str(maxim)+".npy")
    Y=np.load(pathin+"target_vector"+str(maxim)+".npy")

    ##normalization
    mu = np.amax(D,axis=(2,3))
    sigma = np.std(D,axis=(2,3))
    print mu.shape
    for i in range(0,mu.shape[0]):
        #print i
        D[i,0,:,:] = D[i,0,:,:]/mu[i,0]
        D[i,1,:,:] = D[i,1,:,:]/mu[i,1]
        D[i,2,:,:] = D[i,2,:,:]/mu[i,2]


    
    mu_y=np.zeros(nparams)
    sigma_y=np.zeros(nparams)+1.0

    for x in range(0,nparams):
        mu_y[x] = np.mean(Y[:,x])
        sigma_y[x] = np.std(Y[:,x])
        mu_y[x]=0
        sigma_y[x]=1
        Y[:,x] = (Y[:,x] - mu_y[x]) / sigma_y[x]
    
        
    print D.shape 
   
    train_convnet_GZOO(D,Y,ntrain,nval,pathin+"ZOO_model_"+str(ntrain))
    Y_pred=validate_convnet_GZOO(D[pred_index:pred_index+npred,:,:,:],pathin+"ZOO_model_"+str(ntrain)) 
    Y_val=np.copy(Y_pred)   
    Y_pred[:,0]=Y_pred[:,0]*sigma_y[0]+mu_y[0]
    Y_pred[:,1]=Y_pred[:,1]*sigma_y[1]+mu_y[1]
    Y_pred[:,2]=Y_pred[:,2]*sigma_y[2]+mu_y[2]
    Y_val[:,0]=Y[pred_index:pred_index+npred,0]*sigma_y[0]+mu_y[0]
    Y_val[:,1]=Y[pred_index:pred_index+npred,1]*sigma_y[1]+mu_y[1]
    Y_val[:,2]=Y[pred_index:pred_index+npred,2]*sigma_y[2]+mu_y[2]
    #col1 = fits.Column(name='dr7objid', format='K', array=idvec_val)
    col2 = fits.Column(name='a0_1_pred', format='F', array=Y_pred[:,0])
    col3 = fits.Column(name='a0_2_pred', format='F', array=Y_pred[:,1])
    col4 = fits.Column(name='a0_3_pred', format='F', array=Y_pred[:,2])
    col5 = fits.Column(name='a0_1_in', format='F', array=Y_val[:,0])
    col6 = fits.Column(name='a0_2_in', format='F', array=Y_val[:,1])
    col7 = fits.Column(name='a0_3_in', format='F', array=Y_val[:,2])

    cols = fits.ColDefs([col2,col3,col4,col5,col6,col7])
    tbhdu = fits.BinTableHDU.from_columns(cols)
    tbhdu.writeto(pathin+"catalog_DL_3params_single"+str(ntrain)+".fit",clobber='True')
